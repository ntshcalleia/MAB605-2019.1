{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Realimentação de Relevância - Natasha",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntshrocha/MAB605-2019.1/blob/master/Realimenta%C3%A7%C3%A3o_de_Relev%C3%A2ncia_Natasha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igbsGSt3tXDy",
        "colab_type": "text"
      },
      "source": [
        "## Código dos exercícios anteriores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq6Ql7kZXVtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re # expressões regulares\n",
        "import functools # programação funcional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "\n",
        "# UTILS ########################################################################\n",
        "\n",
        "def tokenize(string, separators, stopwords):\n",
        "  regex = re.compile(f'[{\"\".join(separators)}]+')\n",
        "  tokens = re.split(regex, string) # split on separators\n",
        "  tokens = [x.lower() for x in tokens] # lowercase token\n",
        "  tokens = filter(lambda x: x not in stopwords, tokens) # remove stopwords\n",
        "  return list(filter(None, tokens)) # remove empty tokens\n",
        "\n",
        "def incidence_matrix(tokenized_docs, alphabet = None):\n",
        "  # Transforma array de arrays em um único array:\n",
        "  flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "  if alphabet is None:\n",
        "    # Filtra palavras únicas e retorna alfabeto com todas as palavras nos docs:\n",
        "    alphabet = functools.reduce(lambda l, x: l if x in l else l+[x], flatten(tokenized_docs), [])\n",
        "\n",
        "  IM = pd.DataFrame(columns=alphabet)\n",
        "  # Para cada documento:\n",
        "  for i, doc in enumerate(tokenized_docs):\n",
        "    doc_name = f'{i+1}'\n",
        "    # Cria linha para adicionar no dataframe\n",
        "    row = pd.Series(np.zeros(len(alphabet)), index=alphabet, name=doc_name, dtype=int)\n",
        "    # Para cada palavra do documento:\n",
        "    for word in doc:\n",
        "      row[word] += 1\n",
        "    IM = IM.append(row)\n",
        "  return IM\n",
        "\n",
        "def get_tf(matrix):\n",
        "  TF = matrix.copy().applymap(lambda f: 0 if f == 0 else 1 + np.log2(f))\n",
        "  return TF\n",
        "\n",
        "def get_idf(matrix):\n",
        "  N = matrix.shape[0] # Número total de documentos\n",
        "  IDF = matrix.astype(bool).sum() # Conta valores não nulos por coluna\n",
        "  return IDF.apply(lambda n: np.log2(N/n))\n",
        "\n",
        "def get_tf_idf(TF, IDF):\n",
        "  TF = TF.where(TF != 0) # Zeros transformados em NaN para não atrapalhar contas\n",
        "  w = TF.mul(IDF)\n",
        "  return w.fillna(0) # Transforma NaN de volta em 0\n",
        "\n",
        "# MODELO VETORIAL ##############################################################\n",
        "\n",
        "def modelo_vetorial(docs, query):\n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  IM_docs = incidence_matrix(docs)\n",
        "  IM_query = incidence_matrix([query], alphabet = IM_docs.columns)\n",
        "  \n",
        "  # Frequência total de ocorrência dos termos:\n",
        "  TF = get_tf(IM_docs)\n",
        "  TF_query = get_tf(IM_query)\n",
        "  \n",
        "  # Frequência de documento:\n",
        "  IDF = get_idf(IM_docs)\n",
        "  \n",
        "  # Ponderação TF-IDF:\n",
        "  w = get_tf_idf(TF, IDF)\n",
        "  w_query = get_tf_idf(TF_query, IDF)\n",
        "  \n",
        "  rank = {}\n",
        "  \n",
        "  def sim(w1, w2):\n",
        "    return w1.dot(w2)/(np.linalg.norm(w1)*np.linalg.norm(w2))\n",
        "  \n",
        "  for name, vector in w.iterrows():\n",
        "    rank[name] = sim(vector, w_query.T)[0]\n",
        "  \n",
        "  return sorted(rank.items(), key=lambda kv: -kv[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He-w7r3cZX1w",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 8 - Modelo de Rocchio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVq6WfjkRwia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DADOS DO PROBLEMA ############################################################\n",
        "\n",
        "documentos = ['O peã e o caval são pec de xadrez. O caval é o melhor do jog.', 'A jog envolv a torr, o peã e o rei.', 'O peã lac o boi', 'Caval de rodei!', 'Polic o jog no xadrez.']\n",
        "\n",
        "stopwords = ['a', 'o', 'e', 'é', 'de', 'do', 'no', 'são']\n",
        "\n",
        "consulta = 'xadrez peã caval torr'\n",
        "\n",
        "separadores = [' ',',','.','!','?']\n",
        "\n",
        "R = [1, 2] # identificador dos documentos relevantes para a consulta q\n",
        "\n",
        "alpha, beta, gama = 1, 0.75, 0.15 # parâmetros do método de Rocchio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFhrs-l7Rgc2",
        "colab_type": "code",
        "outputId": "04ea4faf-f539-43c7-a957-609e5f94fda7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# MODELO DE ROCCHIO ############################################################\n",
        "\n",
        "def rocchio(docs, query, R, results, alpha = 1, beta = 0.75, gamma = 0.15):\n",
        "  N = len(docs) # Número de documentos da coleção\n",
        "  Dr = [] # Conjunto de documentos relevantes dentre os recuperados\n",
        "  Dn = [] # Conjunto de documentos não relevantes dentre os recuperados\n",
        "  \n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  IM_docs = incidence_matrix(docs)\n",
        "  IM_query = incidence_matrix([query], alphabet = IM_docs.columns)\n",
        "  \n",
        "  # Frequência total de ocorrência dos termos:\n",
        "  TF = get_tf(IM_docs)\n",
        "  TF_query = get_tf(IM_query)\n",
        "  \n",
        "  # Frequência de documento:\n",
        "  IDF = get_idf(IM_docs)\n",
        "  \n",
        "  # Ponderação TF-IDF:\n",
        "  W = get_tf_idf(TF, IDF)\n",
        "  Q = get_tf_idf(TF_query, IDF)\n",
        "\n",
        "  # Separa documentos do conjunto resultado em Dr e Dn\n",
        "  for doc in results:\n",
        "    n = doc[0]\n",
        "    doc_vec = W.loc[n, :]\n",
        "    Dr.append(doc_vec) if (int(n) in R) else Dn.append(doc_vec)\n",
        "  \n",
        "  Nr, Nn = len(Dr), len(Dn) # Número de documentos em Dr e Dn\n",
        "  Dr = np.array(Dr)\n",
        "  Dn = np.array(Dn)\n",
        "  \n",
        "  # Calcula vetor da consulta modificada\n",
        "  Qm = alpha * Q + beta * np.sum(Dr, axis = 0)/Nr - gamma * np.sum(Dn, axis = 0)/Nn\n",
        "  \n",
        "  # Novo rankeamento com a consulta modificada:\n",
        "  rank = {}\n",
        "  \n",
        "  def sim(w1, w2):\n",
        "    return w1.dot(w2)/(np.linalg.norm(w1)*np.linalg.norm(w2))\n",
        "  \n",
        "  for name, vector in W.iterrows():\n",
        "    rank[name] = sim(vector, Qm.T)[0]\n",
        "  \n",
        "  return Qm, sorted(rank.items(), key=lambda kv: -kv[1])\n",
        "\n",
        "# EXEMPLO ############################################################\n",
        "\n",
        "D = [tokenize(doc, separadores, stopwords) for doc in documentos]\n",
        "Q = tokenize(consulta, separadores, stopwords)\n",
        "\n",
        "resultado = modelo_vetorial(D, Q)\n",
        "Qm, rank = rocchio(D, Q, R, resultado, alpha, beta, gama)\n",
        "\n",
        "print(\"\\033[1mRank do modelo vetorial:\\033[0m\")\n",
        "print(resultado)\n",
        "print(\"\\033[1mNovo rank após 1 iteração:\\033[0m\")\n",
        "print(rank)\n",
        "print(\"\\n\\033[1mConsulta modificada:\\033[0m\")\n",
        "Qm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mRank do modelo vetorial:\u001b[0m\n",
            "[('2', 0.4651729931620071), ('1', 0.415053375730601), ('4', 0.21298960013595078), ('5', 0.20532236528436032), ('3', 0.052555274134206874)]\n",
            "\u001b[1mNovo rank após 1 iteração:\u001b[0m\n",
            "[('2', 0.6371955792187908), ('1', 0.6217346178944333), ('4', 0.20973982246898742), ('5', 0.18159559038455), ('3', 0.02368245949389386)]\n",
            "\n",
            "\u001b[1mConsulta modificada:\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>peã</th>\n",
              "      <th>caval</th>\n",
              "      <th>pec</th>\n",
              "      <th>xadrez</th>\n",
              "      <th>melhor</th>\n",
              "      <th>jog</th>\n",
              "      <th>envolv</th>\n",
              "      <th>torr</th>\n",
              "      <th>rei</th>\n",
              "      <th>lac</th>\n",
              "      <th>boi</th>\n",
              "      <th>rodei</th>\n",
              "      <th>polic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.252842</td>\n",
              "      <td>2.247278</td>\n",
              "      <td>0.870723</td>\n",
              "      <td>1.751555</td>\n",
              "      <td>0.870723</td>\n",
              "      <td>0.515876</td>\n",
              "      <td>0.870723</td>\n",
              "      <td>3.192651</td>\n",
              "      <td>0.870723</td>\n",
              "      <td>-0.116096</td>\n",
              "      <td>-0.116096</td>\n",
              "      <td>-0.116096</td>\n",
              "      <td>-0.116096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        peã     caval       pec  ...       boi     rodei     polic\n",
              "1  1.252842  2.247278  0.870723  ... -0.116096 -0.116096 -0.116096\n",
              "\n",
              "[1 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    }
  ]
}