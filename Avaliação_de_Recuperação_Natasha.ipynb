{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Avaliação de Recuperação - Natasha",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntshrocha/MAB605-2019.1/blob/master/Avalia%C3%A7%C3%A3o_de_Recupera%C3%A7%C3%A3o_Natasha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Th-vL2O9Ax",
        "colab_type": "text"
      },
      "source": [
        "# Código dos exercícios anteriores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASwpkl46G3yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re # expressões regulares\n",
        "import functools # programação funcional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "\n",
        "# UTILS ########################################################################\n",
        "\n",
        "def tokenize(string, separators, stopwords):\n",
        "  regex = re.compile(f'[{\"\".join(separators)}]+')\n",
        "  tokens = re.split(regex, string) # split on separators\n",
        "  tokens = [x.lower() for x in tokens] # lowercase token\n",
        "  tokens = filter(lambda x: x not in stopwords, tokens) # remove stopwords\n",
        "  return list(filter(None, tokens)) # remove empty tokens\n",
        "\n",
        "def tokenizer(documents, separators, stopwords):\n",
        "  return [tokenize(doc, separators, stopwords) for doc in documents]\n",
        "\n",
        "def incidence_matrix(tokenized_docs, alphabet = None):\n",
        "  # Transforma array de arrays em um único array:\n",
        "  flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "  if alphabet is None:\n",
        "    # Filtra palavras únicas e retorna alfabeto com todas as palavras nos docs:\n",
        "    alphabet = functools.reduce(lambda l, x: l if x in l else l+[x], flatten(tokenized_docs), [])\n",
        "\n",
        "  IM = pd.DataFrame(columns=alphabet)\n",
        "  # Para cada documento:\n",
        "  for i, doc in enumerate(tokenized_docs):\n",
        "    doc_name = f'{i+1}'\n",
        "    # Cria linha para adicionar no dataframe\n",
        "    row = pd.Series(np.zeros(len(alphabet)), index=alphabet, name=doc_name, dtype=int)\n",
        "    # Para cada palavra do documento:\n",
        "    for word in doc:\n",
        "      row[word] += 1\n",
        "    IM = IM.append(row)\n",
        "  return IM\n",
        "\n",
        "def sort(rank):\n",
        "  return sorted(rank.items(), key=lambda kv: -kv[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6EzHanLKHja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODELO VETORIAL ##############################################################\n",
        "\n",
        "def get_tf(matrix):\n",
        "  TF = matrix.copy().applymap(lambda f: 0 if f == 0 else 1 + np.log2(f))\n",
        "  return TF\n",
        "\n",
        "def get_idf(matrix):\n",
        "  N = matrix.shape[0] # Número total de documentos\n",
        "  IDF = matrix.astype(bool).sum() # Conta valores não nulos por coluna\n",
        "  return IDF.apply(lambda n: np.log2(N/n))\n",
        "\n",
        "def get_tf_idf(TF, IDF):\n",
        "  TF = TF.where(TF != 0) # Zeros transformados em NaN para não atrapalhar contas\n",
        "  w = TF.mul(IDF)\n",
        "  return w.fillna(0) # Transforma NaN de volta em 0\n",
        "\n",
        "def vetorial(docs, stopwords, query, seps):\n",
        "  # Pré-processamento dos docs e query:\n",
        "  tokens_query = tokenize(query, seps, stopwords)\n",
        "  tokens_docs = tokenizer(docs, seps, stopwords)\n",
        "\n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  IM_docs = incidence_matrix(tokens_docs)\n",
        "  IM_query = incidence_matrix([tokens_query], alphabet = IM_docs.columns)\n",
        "  \n",
        "  # Frequência total de ocorrência dos termos:\n",
        "  TF = get_tf(IM_docs)\n",
        "  TF_query = get_tf(IM_query)\n",
        "  \n",
        "  # Frequência de documento:\n",
        "  IDF = get_idf(IM_docs)\n",
        "  \n",
        "  # Ponderação TF-IDF:\n",
        "  w = get_tf_idf(TF, IDF)\n",
        "  w_query = get_tf_idf(TF_query, IDF)\n",
        "  \n",
        "  rank = {}\n",
        "  \n",
        "  def sim(w1, w2):\n",
        "    return w1.dot(w2)/(np.linalg.norm(w1)*np.linalg.norm(w2))\n",
        "  \n",
        "  for name, vector in w.iterrows():\n",
        "    rank[name] = sim(vector, w_query.T)[0]\n",
        "  \n",
        "  return sort(rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw4GZZfHLrIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODELO PROBABILÍSTICO ########################################################\n",
        "\n",
        "def avg_doclen(docs):\n",
        "  N = len(docs) # número total de documentos\n",
        "  return functools.reduce(lambda avg_len, doc: avg_len + len(doc)/N, docs, 0)\n",
        "\n",
        "def BM25(docs, stopwords, query, seps, K1=1, b=0.75):\n",
        "  # Pré-processamento dos docs e query:\n",
        "  tokens_query = tokenize(query, seps, stopwords)\n",
        "  tokens_docs = tokenizer(docs, seps, stopwords)\n",
        "\n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  IM_docs = incidence_matrix(tokens_docs)\n",
        "  IM_query = incidence_matrix([tokens_query], alphabet = IM_docs.columns)\n",
        "  \n",
        "  # Dados sobre documentos\n",
        "  avg_len = avg_doclen(tokens_docs)\n",
        "  N = len(docs)\n",
        "  n = IM_docs.astype(bool).sum() # Conta a quantidade de valores não nulos por coluna\n",
        "  \n",
        "  # Construção do Beta\n",
        "  B = (K1 + 1)*IM_docs\n",
        "  \n",
        "  for i, doc in enumerate(tokens_docs):\n",
        "    divisor = K1 * (1 - b + b*(len(doc)/avg_len)) + IM_docs.iloc[i]\n",
        "    B.iloc[i] = B.iloc[i]/divisor\n",
        "  \n",
        "  rank = {}\n",
        "  \n",
        "  for name, row in B.iterrows():\n",
        "    rank[name] = 0\n",
        "    sim = row * np.log((N - n + 0.5)/(n + 0.5))\n",
        "    for word in tokens_query:\n",
        "      rank[name] += sim[word]\n",
        "  \n",
        "  return sort(rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgPUMHeeNNUb",
        "colab_type": "text"
      },
      "source": [
        "## Exercício 7 - Avaliação de Recuperação de Informação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7P-9vrtF162",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DADOS DO PROBLEMA ############################################################\n",
        "\n",
        "documentos = ['O peã e o caval são pec de xadrez. O caval é o melhor do jog.', 'A jog envolv a torr, o peã e o rei.', 'O peã lac o boi', 'Caval de rodei!', 'Polic o jog no xadrez.']\n",
        "\n",
        "stopwords = ['a', 'o', 'e', 'é', 'de', 'do', 'no', 'são']\n",
        "\n",
        "consulta = 'xadrez peã caval torr'\n",
        "\n",
        "separadores = [' ',',','.','!','?']\n",
        "\n",
        "R = [1, 2] # identificador dos documentos relevantes para a consulta q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4eCwfwSMYf7",
        "colab_type": "code",
        "outputId": "c0ab5444-c136-41c6-e17a-6da812d1b7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# RESULTADOS OBTIDOS ###########################################################\n",
        "\n",
        "resultado_vetorial = vetorial(documentos, stopwords, consulta, separadores)\n",
        "resultado_bm25 = BM25(documentos, stopwords, consulta, separadores)\n",
        "\n",
        "print(resultado_vetorial)\n",
        "print(resultado_bm25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('2', 0.4651729931620071), ('1', 0.415053375730601), ('4', 0.21298960013595078), ('5', 0.20532236528436032), ('3', 0.052555274134206874)]\n",
            "[('2', 0.6968137618714486), ('4', 0.41411967584149284), ('1', 0.37779338848697586), ('5', 0.37127970937513144), ('3', -0.37127970937513144)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVIfegahFDt6",
        "colab_type": "code",
        "outputId": "17d20ea9-6b28-4380-8a5f-10f37a8fb927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# REVOCAÇÃO E PRECISÃO, CONSIDERANDO TODOS OS DOCUMENTOS RECUPERADOS ###########\n",
        "\n",
        "def recall(resultado, relevantes):\n",
        "  if (type(resultado[0]) == tuple):\n",
        "    resultado = [int(x[0]) for x in resultado if x[1] >= 0]\n",
        "  R_recuperados = [x for x in resultado if x in relevantes]\n",
        "  return len(R_recuperados)/len(relevantes)\n",
        "\n",
        "def precision(resultado, relevantes):\n",
        "  if (type(resultado[0]) == tuple):\n",
        "    resultado = [int(x[0]) for x in resultado if x[1] >= 0]\n",
        "  R_recuperados = [x for x in resultado if x in relevantes]\n",
        "  return len(R_recuperados)/len(resultado)\n",
        "\n",
        "print(\"\\033[1mModelo Vetorial:\\033[0m\")\n",
        "print(f'Revocação: {recall(resultado_vetorial, R)}')\n",
        "print(f'Precisão: {precision(resultado_vetorial, R)}\\n')\n",
        "\n",
        "print(\"\\033[1mBM25:\\033[0m\")\n",
        "print(f'Revocação: {recall(resultado_bm25, R)}')\n",
        "print(f'Precisão: {precision(resultado_bm25, R)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mModelo Vetorial:\u001b[0m\n",
            "Revocação: 1.0\n",
            "Precisão: 0.4\n",
            "\n",
            "\u001b[1mBM25:\u001b[0m\n",
            "Revocação: 1.0\n",
            "Precisão: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OFfUNoretjQ",
        "colab_type": "code",
        "outputId": "c70ab6a0-55a0-4f0d-b8ad-2543e82806c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# REVOCAÇÃO E PRECISÃO A CADA RELEVANTE RECUPERADO #############################\n",
        "\n",
        "def make_recall_vs_precision_table(resultado, relevantes):\n",
        "  resultado = [int(x[0]) for x in resultado if x[1] >= 0]\n",
        "  table = []\n",
        "  m = 0\n",
        "  for doc in resultado:\n",
        "    if doc in relevantes:\n",
        "      rank = resultado.index(doc)\n",
        "      m += 1\n",
        "      table.append(recall(resultado[:rank+1], relevantes))\n",
        "      table.append(precision(resultado[:rank+1], relevantes))\n",
        "  \n",
        "  table = np.reshape(table, (m,2))\n",
        "  \n",
        "  return pd.DataFrame(table, columns=[\"Revocação\", \"Precisão\"])\n",
        "\n",
        "table_vetorial = make_recall_vs_precision_table(resultado_vetorial, R)\n",
        "table_bm25 = make_recall_vs_precision_table(resultado_bm25, R)\n",
        "\n",
        "print(\"\\033[1mModelo Vetorial:\\033[0m\")\n",
        "print(table_vetorial.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\033[1mBM25:\\033[0m\")\n",
        "print(table_bm25.to_string(index=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mModelo Vetorial:\u001b[0m\n",
            " Revocação  Precisão\n",
            "       0.5       1.0\n",
            "       1.0       1.0\n",
            "\n",
            "\u001b[1mBM25:\u001b[0m\n",
            " Revocação  Precisão\n",
            "       0.5  1.000000\n",
            "       1.0  0.666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8y5h_6ve1cd",
        "colab_type": "code",
        "outputId": "801bc472-d233-47df-e6c6-ab44ac4e75cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "# PRECISÃO INTERPOLADA PARA CADA UM DOS 11 NÍVEIS PADRÃO DE REVOCAÇÃO ##########\n",
        "\n",
        "def precisao_interpolada(resultado, relevantes):\n",
        "  table1 = make_recall_vs_precision_table(resultado, relevantes)\n",
        "  \n",
        "  table2 = pd.DataFrame([[i*0.1, 0] for i in range(0,11)], columns=['Revocação', 'Precisão'])\n",
        "  \n",
        "  for nivel in table1.items():\n",
        "    revocacao = nivel[1][0]\n",
        "    precisao = nivel[1][1]\n",
        "    \n",
        "    # Atualiza todos os menores\n",
        "    i = 0\n",
        "    while (i * 0.1) <= revocacao:\n",
        "      atual = table2.loc[i, 'Precisão']\n",
        "      if precisao > atual:\n",
        "        table2.loc[i, 'Precisão'] = precisao\n",
        "      i += 1\n",
        "  \n",
        "  return table2\n",
        "\n",
        "plt_vetorial = (precisao_interpolada(resultado_vetorial, R) * 100).plot(kind='line', x=\"Revocação\", y=\"Precisão\", label=\"Vetorial\")\n",
        "(precisao_interpolada(resultado_bm25, R) * 100).plot(kind='line', x=\"Revocação\", y=\"Precisão\", ax=plt_vetorial, label=\"BM25\", title=\"\\nPrecisão Interpolada\");"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAElCAYAAADtFjXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4iaCSi6edZX",
        "colab_type": "code",
        "outputId": "9b312fa9-e8d2-43bb-92ef-e813b6fe3d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# MEDIDA F1, CONSIDERANDO TODOS OS DOCUMENTOS RECUPERADOS ######################\n",
        "\n",
        "def F(resultado, relevantes, beta = 1):\n",
        "  resultado = [int(x[0]) for x in resultado if x[1] >= 0]\n",
        "  P = []\n",
        "  r = []\n",
        "  for doc in resultado:\n",
        "    rank = resultado.index(doc)\n",
        "    P.append(recall(resultado[:rank+1], relevantes))\n",
        "    r.append(precision(resultado[:rank+1], relevantes))\n",
        "  \n",
        "  P = np.array(P)\n",
        "  r = np.array(r)\n",
        "  \n",
        "  return ((1 + beta**2) * P * r)/((beta**2 * P) + r)\n",
        "\n",
        "print(\"\\033[1mModelo Vetorial:\\033[0m\")\n",
        "print(f'F1 = {F(resultado_vetorial, R, 1)}')\n",
        "\n",
        "print(\"\\n\\033[1mBM25:\\033[0m\")\n",
        "print(f'F1 = {F(resultado_bm25, R, 1)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mModelo Vetorial:\u001b[0m\n",
            "F1 = [0.66666667 1.         0.8        0.66666667 0.57142857]\n",
            "\n",
            "\u001b[1mBM25:\u001b[0m\n",
            "F1 = [0.66666667 0.5        0.8        0.66666667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8EHaZKZe8gl",
        "colab_type": "code",
        "outputId": "965d5451-1db6-408b-b655-6e0761c5f4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# PRECISÃO MÉDIA PARA A CONSULTA (MAPi) ########################################\n",
        "\n",
        "def MAP(resultado, relevantes):\n",
        "  P = make_recall_vs_precision_table(resultado, relevantes)['Precisão']\n",
        "  return P.mean()\n",
        "\n",
        "print(\"\\033[1mModelo Vetorial:\\033[0m\")\n",
        "print(f'MAP = {MAP(resultado_vetorial, R)}')\n",
        "\n",
        "print(\"\\n\\033[1mBM25:\\033[0m\")\n",
        "print(f'MAP = {MAP(resultado_bm25, R)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mModelo Vetorial:\u001b[0m\n",
            "MAP = 1.0\n",
            "\n",
            "\u001b[1mBM25:\u001b[0m\n",
            "MAP = 0.8333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}