{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recuperação de Informação - Natasha",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNp1wuvGTcjA",
        "colab_type": "text"
      },
      "source": [
        "#Natasha Rocha - DRE: 112079422"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDU9as_9E7qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re # expressões regulares\n",
        "import functools # programação funcional\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections # ordered dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRygPlua3LEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dados que serão usados nos exemplos:\n",
        "M = ['O peã e o caval são pec de xadrez. O caval é o melhor do jog.'\n",
        "     ,'A jog envolv a torr, o peã e o rei.'\n",
        "     ,'O peã lac o boi'\n",
        "     ,'Caval de rodei!'\n",
        "     ,'Polic o jog no xadrez.']\n",
        "\n",
        "stopwords = ['a', 'o', 'e', 'é', 'de', 'do', 'no', 'são']\n",
        "\n",
        "q = 'xadrez peã caval torr'\n",
        "\n",
        "separadores = [' ',',','.','!','?']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4COMzn8zDj6",
        "colab_type": "text"
      },
      "source": [
        "##Exercício 4: Modelo Booleano"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuXu7sbp0Gne",
        "colab_type": "code",
        "outputId": "9a0984a4-3e5e-4ff5-8cfb-3e01a0d00e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# TOKENIZAÇÃO DOS DOCUMENTOS ##############################################################################################################\n",
        "def tokenize(string, seps):\n",
        "  regex = re.compile(f'[{\"\".join(seps)}]+') # regex que identifica conjunto de separadores. Identifica \"!\", \", \" ou \". \", por exemplo.\n",
        "  tokens = re.split(regex, string)\n",
        "  return list(filter(None, tokens)) # remove tokens vazios\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "tokenize(M[0], separadores)\n",
        "\n",
        "## OBS: Se houverem strings ou certos caracteres especiais nos seps será preciso tratar esses casos.\n",
        "## No caso isso não foi necessário, então esses edge cases não foram implementados - ainda."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'peã',\n",
              " 'e',\n",
              " 'o',\n",
              " 'caval',\n",
              " 'são',\n",
              " 'pec',\n",
              " 'de',\n",
              " 'xadrez',\n",
              " 'O',\n",
              " 'caval',\n",
              " 'é',\n",
              " 'o',\n",
              " 'melhor',\n",
              " 'do',\n",
              " 'jog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCOmofeN2bBC",
        "colab_type": "code",
        "outputId": "973104c6-9f0d-457f-d1e4-a83d9b68d262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# NORMALIZAÇÃO DOS TERMOS E ELIMINAÇÃO DE STOPWORDS #######################################################################################\n",
        "def remove_stopwords(words, stopwords):\n",
        "  def process_words(obj, word):\n",
        "    _word = word.lower() # Mapeamento para lowercase\n",
        "    if _word not in stopwords: # Filtragem de stopwords\n",
        "      obj.append(_word)\n",
        "    return obj\n",
        "  \n",
        "  return functools.reduce(process_words, words, []) # Reduce consegue realizar o mapeamento e filtragem em uma única passada pelo array\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "tokens_0 = tokenize(M[0], separadores)\n",
        "remove_stopwords(tokens_0, stopwords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['peã', 'caval', 'pec', 'xadrez', 'caval', 'melhor', 'jog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbv6h_dJ5Vo6",
        "colab_type": "code",
        "outputId": "eb37e0c4-f387-4414-d615-1f37df9153f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# CRIAÇÃO DA MATRIZ DE INCIDÊNCIAS COM FREQUÊNCIA #########################################################################################\n",
        "def incidence_matrix(tokenized_docs, alphabet = None):\n",
        "  # Transforma array de arrays em um único array:\n",
        "  flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "  if alphabet is None:\n",
        "    # Filtra palavras únicas e retorna alfabeto com todas as palavras nos docs:\n",
        "    alphabet = functools.reduce(lambda l, x: l if x in l else l+[x], flatten(tokenized_docs), [])\n",
        "\n",
        "  IM = pd.DataFrame(columns=alphabet)\n",
        "  # Para cada documento:\n",
        "  for i, doc in enumerate(tokenized_docs):\n",
        "    doc_name = f'doc{i}'\n",
        "    # Cria linha para adicionar no dataframe\n",
        "    row = pd.Series(np.zeros(len(alphabet)), index=alphabet, name=doc_name, dtype=int)\n",
        "    # Para cada palavra do documento:\n",
        "    for word in doc:\n",
        "      row[word] += 1\n",
        "    IM = IM.append(row)\n",
        "  return IM\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "tokenized_docs = [tokenize(doc, separadores) for doc in M]\n",
        "clean_tokens = [remove_stopwords(tokens, stopwords) for tokens in tokenized_docs]\n",
        "incidence_matrix(clean_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>peã</th>\n",
              "      <th>caval</th>\n",
              "      <th>pec</th>\n",
              "      <th>xadrez</th>\n",
              "      <th>melhor</th>\n",
              "      <th>jog</th>\n",
              "      <th>envolv</th>\n",
              "      <th>torr</th>\n",
              "      <th>rei</th>\n",
              "      <th>lac</th>\n",
              "      <th>boi</th>\n",
              "      <th>rodei</th>\n",
              "      <th>polic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     peã caval pec xadrez melhor jog envolv torr rei lac boi rodei polic\n",
              "doc0   1     2   1      1      1   1      0    0   0   0   0     0     0\n",
              "doc1   1     0   0      0      0   1      1    1   1   0   0     0     0\n",
              "doc2   1     0   0      0      0   0      0    0   0   1   1     0     0\n",
              "doc3   0     1   0      0      0   0      0    0   0   0   0     1     0\n",
              "doc4   0     0   0      1      0   1      0    0   0   0   0     0     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8glNi-5r6vt-",
        "colab_type": "code",
        "outputId": "73799962-8944-40ed-8803-2f3b319d0aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# MODELO BOOLEANO #########################################################################################################################\n",
        "def boolean_model(docs, stopwords, query, seps):  \n",
        "  # Pré-processamento dos docs e query:\n",
        "  tokens_query = tokenize(query, seps)\n",
        "  tokens_docs = [tokenize(doc, seps) for doc in docs]\n",
        "  \n",
        "  clean_query = remove_stopwords(tokens_query, stopwords)\n",
        "  clean_docs = [remove_stopwords(tokens, stopwords) for tokens in tokens_docs]\n",
        "\n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  matrix = incidence_matrix(clean_docs)\n",
        "  \n",
        "  # Modelo booleano:\n",
        "  boolean = {'AND': [], 'OR': []}\n",
        "  \n",
        "  # AND\n",
        "  for i, doc in matrix.iterrows(): # Para cada linha da matriz (para cada documento)\n",
        "    found = True\n",
        "    for word in clean_query:\n",
        "      if doc[word] == 0:\n",
        "        found = False\n",
        "        break\n",
        "    if found:\n",
        "      boolean['AND'].append(doc.name)\n",
        "        \n",
        "  # OR\n",
        "  for i, doc in matrix.iterrows(): # Para cada linha da matriz (para cada documento)\n",
        "    found = False\n",
        "    for word in clean_query:\n",
        "      if doc[word] != 0:\n",
        "        found = True\n",
        "        break\n",
        "    if found:\n",
        "      boolean['OR'].append(doc.name)\n",
        "  \n",
        "  return boolean\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "boolean_model(M, stopwords, q, separadores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AND': [], 'OR': ['doc0', 'doc1', 'doc2', 'doc3', 'doc4']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Smxw9CnX8Ng",
        "colab_type": "text"
      },
      "source": [
        "##Exercício 5: Modelo Vetorial (com ponderação TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5nLAJV0bH_E",
        "colab_type": "code",
        "outputId": "d6356f68-6e1c-4167-9ac5-50a1c18dcb70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# TERM FREQUENCY ##########################################################################################################################\n",
        "def get_tf(matrix):\n",
        "  TF = matrix.copy().applymap(lambda f: 0 if f == 0 else 1 + np.log2(f))\n",
        "  return TF\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "IM = incidence_matrix(clean_tokens)\n",
        "get_tf(IM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>peã</th>\n",
              "      <th>caval</th>\n",
              "      <th>pec</th>\n",
              "      <th>xadrez</th>\n",
              "      <th>melhor</th>\n",
              "      <th>jog</th>\n",
              "      <th>envolv</th>\n",
              "      <th>torr</th>\n",
              "      <th>rei</th>\n",
              "      <th>lac</th>\n",
              "      <th>boi</th>\n",
              "      <th>rodei</th>\n",
              "      <th>polic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      peã  caval  pec  xadrez  melhor  jog  envolv  torr  rei  lac  boi  \\\n",
              "doc0  1.0    2.0  1.0     1.0     1.0  1.0     0.0   0.0  0.0  0.0  0.0   \n",
              "doc1  1.0    0.0  0.0     0.0     0.0  1.0     1.0   1.0  1.0  0.0  0.0   \n",
              "doc2  1.0    0.0  0.0     0.0     0.0  0.0     0.0   0.0  0.0  1.0  1.0   \n",
              "doc3  0.0    1.0  0.0     0.0     0.0  0.0     0.0   0.0  0.0  0.0  0.0   \n",
              "doc4  0.0    0.0  0.0     1.0     0.0  1.0     0.0   0.0  0.0  0.0  0.0   \n",
              "\n",
              "      rodei  polic  \n",
              "doc0    0.0    0.0  \n",
              "doc1    0.0    0.0  \n",
              "doc2    0.0    0.0  \n",
              "doc3    1.0    0.0  \n",
              "doc4    0.0    1.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqf_A4wicidf",
        "colab_type": "code",
        "outputId": "d1d8fd00-fb14-4363-ca46-00a082997d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# INVERSE DOCUMENT FREQUENCY ##############################################################################################################\n",
        "def get_idf(matrix):\n",
        "  N = matrix.shape[0] # Número total de documentos\n",
        "  IDF = matrix.astype(bool).sum() # Conta a quantidade de valores não nulos por coluna\n",
        "  return IDF.apply(lambda n: np.log2(N/n))\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "get_idf(IM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "peã       0.736966\n",
              "caval     1.321928\n",
              "pec       2.321928\n",
              "xadrez    1.321928\n",
              "melhor    2.321928\n",
              "jog       0.736966\n",
              "envolv    2.321928\n",
              "torr      2.321928\n",
              "rei       2.321928\n",
              "lac       2.321928\n",
              "boi       2.321928\n",
              "rodei     2.321928\n",
              "polic     2.321928\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-p2RflEdHP_",
        "colab_type": "code",
        "outputId": "3944dc1b-2c68-4ab8-b737-e2b0d2131f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def get_tf_idf(TF, IDF):\n",
        "  TF = TF.where(TF != 0) # Zeros são transformados em NaN para não interferirem nas contas\n",
        "  w = TF.mul(IDF)\n",
        "  return w.fillna(0) # Transforma NaN de volta em 0\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "get_tf_idf(get_tf(IM), get_idf(IM))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>peã</th>\n",
              "      <th>caval</th>\n",
              "      <th>pec</th>\n",
              "      <th>xadrez</th>\n",
              "      <th>melhor</th>\n",
              "      <th>jog</th>\n",
              "      <th>envolv</th>\n",
              "      <th>torr</th>\n",
              "      <th>rei</th>\n",
              "      <th>lac</th>\n",
              "      <th>boi</th>\n",
              "      <th>rodei</th>\n",
              "      <th>polic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc0</th>\n",
              "      <td>0.736966</td>\n",
              "      <td>2.643856</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>1.321928</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.736966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc1</th>\n",
              "      <td>0.736966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.736966</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc2</th>\n",
              "      <td>0.736966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.321928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.321928</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>doc4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.321928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.736966</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.321928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           peã     caval       pec    xadrez    melhor       jog    envolv  \\\n",
              "doc0  0.736966  2.643856  2.321928  1.321928  2.321928  0.736966  0.000000   \n",
              "doc1  0.736966  0.000000  0.000000  0.000000  0.000000  0.736966  2.321928   \n",
              "doc2  0.736966  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "doc3  0.000000  1.321928  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "doc4  0.000000  0.000000  0.000000  1.321928  0.000000  0.736966  0.000000   \n",
              "\n",
              "          torr       rei       lac       boi     rodei     polic  \n",
              "doc0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "doc1  2.321928  2.321928  0.000000  0.000000  0.000000  0.000000  \n",
              "doc2  0.000000  0.000000  2.321928  2.321928  0.000000  0.000000  \n",
              "doc3  0.000000  0.000000  0.000000  0.000000  2.321928  0.000000  \n",
              "doc4  0.000000  0.000000  0.000000  0.000000  0.000000  2.321928  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKYXxhtEi_62",
        "colab_type": "code",
        "outputId": "15169ba0-54c3-4490-e863-082bbbc02d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def vector_space_model(docs, stopwords, query, seps):\n",
        "  # Pré-processamento dos docs e query:\n",
        "  tokens_query = tokenize(query, seps)\n",
        "  tokens_docs = [tokenize(doc, seps) for doc in docs]\n",
        "  \n",
        "  clean_query = remove_stopwords(tokens_query, stopwords)\n",
        "  clean_docs = [remove_stopwords(tokens, stopwords) for tokens in tokens_docs]\n",
        "\n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  IM_docs = incidence_matrix(clean_docs)\n",
        "  IM_query = incidence_matrix([clean_query], alphabet = IM_docs.columns)\n",
        "  \n",
        "  # Frequência total de ocorrência dos termos:\n",
        "  TF = get_tf(IM_docs)\n",
        "  TF_query = get_tf(IM_query)\n",
        "  \n",
        "  # Frequência de documento:\n",
        "  IDF = get_idf(IM_docs)\n",
        "  \n",
        "  # Ponderação TF-IDF:\n",
        "  w = get_tf_idf(TF, IDF)\n",
        "  w_query = get_tf_idf(TF_query, IDF)\n",
        "  \n",
        "  rank = {}\n",
        "  \n",
        "  def sim(w1, w2):\n",
        "    return w1.dot(w2)/(np.linalg.norm(w1)*np.linalg.norm(w2))\n",
        "  \n",
        "  for name, vector in w.iterrows():\n",
        "    rank[name] = sim(vector, w_query.T)[0]\n",
        "  \n",
        "  return rank\n",
        "\n",
        "vector_space_model(M, stopwords, q, separadores)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc0': 0.415053375730601,\n",
              " 'doc1': 0.4651729931620071,\n",
              " 'doc2': 0.052555274134206874,\n",
              " 'doc3': 0.21298960013595078,\n",
              " 'doc4': 0.20532236528436032}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqeM17fOiUCx",
        "colab_type": "text"
      },
      "source": [
        "##Exercício 6: Modelo Probabilístico (BM25)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpGOXhQhifGW",
        "colab_type": "code",
        "outputId": "837b8138-bdd7-40d8-c484-0e08e793cfcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# AVERAGE DOCUMENT LENGTH #################################################################################################################\n",
        "def avg_doclen(docs):\n",
        "  N = len(docs) # número total de documentos\n",
        "  return functools.reduce(lambda avg_len, doc: avg_len + len(doc)/N, docs, 0)\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "docs = [tokenize(doc, separadores) for doc in M]\n",
        "docs = [remove_stopwords(tokens, stopwords) for tokens in docs]\n",
        "\n",
        "avg_doclen(docs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amibky0T0MN5",
        "colab_type": "code",
        "outputId": "cfa72c48-78ed-417e-dd64-ab8900a6e83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def probabilistic_model(docs, stopwords, query, seps, K1=1, b=0.75):\n",
        "  # Pré-processamento dos docs e query:\n",
        "  tokens_query = tokenize(query, seps)\n",
        "  tokens_docs = [tokenize(doc, seps) for doc in docs]\n",
        "  \n",
        "  clean_query = remove_stopwords(tokens_query, stopwords)\n",
        "  clean_docs = [remove_stopwords(tokens, stopwords) for tokens in tokens_docs]\n",
        "\n",
        "  # Criação da matriz de incidência com frequência:\n",
        "  IM_docs = incidence_matrix(clean_docs)\n",
        "  IM_query = incidence_matrix([clean_query], alphabet = IM_docs.columns)\n",
        "  \n",
        "  # Dados sobre documentos\n",
        "  avg_len = avg_doclen(clean_docs)\n",
        "  N = len(docs)\n",
        "  n = IM_docs.astype(bool).sum() # Conta a quantidade de valores não nulos por coluna\n",
        "  \n",
        "  # Construção do Beta\n",
        "  B = (K1 + 1)*IM_docs\n",
        "  \n",
        "  for i, doc in enumerate(clean_docs):\n",
        "    divisor = K1 * (1 - b + b*(len(doc)/avg_len)) + IM_docs.iloc[i]\n",
        "    B.iloc[i] = B.iloc[i]/divisor\n",
        "  \n",
        "  rank = {}\n",
        "  \n",
        "  for name, row in B.iterrows():\n",
        "    rank[name] = 0\n",
        "    sim = row * np.log((N - n + 0.5)/(n + 0.5))\n",
        "    for word in clean_query:\n",
        "      rank[name] += sim[word]\n",
        "  \n",
        "  return rank\n",
        "\n",
        "# EXEMPLO #################################################################################################################################\n",
        "probabilistic_model(M, stopwords, q, separadores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc0': 0.37779338848697586,\n",
              " 'doc1': 0.6968137618714486,\n",
              " 'doc2': -0.37127970937513144,\n",
              " 'doc3': 0.41411967584149284,\n",
              " 'doc4': 0.37127970937513144}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    }
  ]
}